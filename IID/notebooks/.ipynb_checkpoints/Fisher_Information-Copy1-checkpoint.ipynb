{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import vector_to_parameters, parameters_to_vector\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import utils\n",
    "from torchsummary import summary\n",
    "import models\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from captum.attr import LayerConductance\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import cm\n",
    "from copy import deepcopy\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    model_file='iid_clean_model.pt'\n",
    "    data='fmnist'\n",
    "    bs = 256\n",
    "    device = 'cuda:0'\n",
    "    lr = 0.1\n",
    "    moment = 0.9\n",
    "    wd = 0\n",
    "    epochs=50\n",
    "    nesterov = True\n",
    "    base_class = 5\n",
    "    target_class = 7\n",
    "    poison_frac = 0.05\n",
    "    pattern_type='+'\n",
    "    top_frac = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = utils.get_datasets(args.data)\n",
    "idxs = (val_dataset.targets == args.base_class).nonzero().flatten().tolist()\n",
    "poisoned_val_set = utils.DatasetSplit(copy.deepcopy(val_dataset), idxs)\n",
    "utils.poison_dataset(poisoned_val_set.dataset, args, poison_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader =  DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, num_workers=2, pin_memory=True)\n",
    "poisoned_val_loader = DataLoader(poisoned_val_set, batch_size=args.bs, shuffle=False, num_workers=0, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_clean = torch.load(args.model_file).eval()\n",
    "model_adv = torch.load('iid_nodefense_model.pt')\n",
    "criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "model_params = parameters_to_vector(model_adv.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_diag_fisher(model_params, data_loader):\n",
    "    \n",
    "    model = models.get_model(args.data)\n",
    "    vector_to_parameters(model_params, model.parameters())\n",
    "    params = {n: p for n, p in model.named_parameters() if p.requires_grad}\n",
    "    precision_matrices = {}\n",
    "    for n, p in deepcopy(params).items():\n",
    "        p.data.zero_()\n",
    "        precision_matrices[n] = p.data\n",
    "        \n",
    "        \n",
    "    model.eval()\n",
    "    for _, (inputs, labels) in enumerate(data_loader):\n",
    "        model.zero_grad()\n",
    "        inputs = inputs.to(device=args.device, non_blocking=True)\n",
    "       \n",
    "        output = model(inputs).view(1, -1)\n",
    "        label = output.max(1)[1].view(-1)\n",
    "        loss = F.nll_loss(F.log_softmax(output, dim=1), label)\n",
    "        print(loss)\n",
    "        loss.backward()\n",
    "    \n",
    "        for n, p in model.named_parameters():\n",
    "            precision_matrices[n].data += (p.grad.data ** 2) / len(data_loader.dataset)\n",
    "            \n",
    "    return parameters_to_vector(precision_matrices.values()).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([])\n",
      "torch.Size([])\n",
      "torch.Size([])\n",
      "torch.Size([])\n"
     ]
    }
   ],
   "source": [
    "adv_params = parameters_to_vector(model_adv.parameters())\n",
    "clean_params = parameters_to_vector(model_clean.parameters())\n",
    "_, indices = comp_diag_fisher(adv_params, poisoned_val_loader).sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_indices_idx = math.floor(len(indices)*args.top_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_params_adv = adv_params[indices[-top_indices_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_params_clean = clean_params[indices[-top_indices_idx:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5055005408865205"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sign(top_params_clean) == torch.sign(top_params_adv)).sum().item() / len(indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda2893f7c78e4248a9bda8fc39f732a94d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

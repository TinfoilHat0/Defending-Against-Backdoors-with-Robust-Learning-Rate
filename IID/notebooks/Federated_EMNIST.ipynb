{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "import helper\n",
    "import utils\n",
    "import models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.nn.utils import parameters_to_vector, vector_to_parameters\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    data='fedemnist'\n",
    "    bs=128\n",
    "    device='cuda:0'\n",
    "    lr=0.01\n",
    "    moment=0.9\n",
    "    wd=0\n",
    "    epoch=100\n",
    "    nesterov=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class H5Dataset(Dataset):\n",
    "    def __init__(self, dataset, client_id):\n",
    "        self.targets = torch.LongTensor(dataset[client_id]['label'])\n",
    "        self.inputs = torch.Tensor(dataset[client_id]['pixels'])\n",
    "        shape = self.inputs.shape\n",
    "        self.inputs = self.inputs.view(shape[0], 1, shape[1], shape[2])\n",
    "        \n",
    "    def classes(self):\n",
    "        return torch.unique(self.targets)\n",
    "    \n",
    "    def __add__(self, other): \n",
    "        self.targets = torch.cat( (self.targets, other.targets), 0)\n",
    "        self.inputs = torch.cat( (self.inputs, other.inputs), 0)\n",
    "        return self\n",
    "    \n",
    "    def to(self, device):\n",
    "        self.targets = self.targets.to(device)\n",
    "        self.inputs = self.inputs.to(device)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.targets.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        inp, target = self.inputs[item], self.targets[item]\n",
    "        return inp, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../data/Fed_EMNIST/fed_emnist_digitsonly_train.h5'\n",
    "val_dir = '../data/Fed_EMNIST/fed_emnist_digitsonly_test.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = h5py.File(train_dir, 'r')['examples']\n",
    "valset = h5py.File(val_dir, 'r')['examples']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = [*dataset.keys()]\n",
    "user_dict = {}\n",
    "for i in range(len(users)):\n",
    "    user_dict[users[i]] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in tqdm(user_dict):\n",
    "    user_trainset = H5Dataset(trainset, key)\n",
    "    user_valset = H5Dataset(valset, key)\n",
    "    torch.save(user_data, f'../data/Fed_EMNIST/user_trainsets/user_{user_dict[key]}_trainset.pt')\n",
    "    torch.save(user_data, f'../data/Fed_EMNIST/user_valsets/user_{user_dict[key]}_valset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../data/Fed_EMNIST/fed_emnist_all_trainset.pt'\n",
    "val_dir = '../data/Fed_EMNIST/fed_emnist_all_valset.pt'\n",
    "\n",
    "val_dataset = torch.load(val_dir)\n",
    "train_dataset = torch.load(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=args.bs, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader =  DataLoader(val_dataset, batch_size=args.bs, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.get_model(args.data).to(args.device)\n",
    "criterion = nn.CrossEntropyLoss().to(args.device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=args.lr, momentum=args.moment, weight_decay=args.wd,\\\n",
    "                            nesterov=args.nesterov)\n",
    "#scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpyed = copy.deepcopy(params.detach_())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpyed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_to_parameters(params, model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_to_vector(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('fed-emnist')\n",
    "start_time, end_time = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "start_time.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "for rnd in tqdm(range(1, args.epoch+1)):\n",
    "    model.train()\n",
    "    train_loss, train_acc = 0.0, 0.0\n",
    "    for _, (inputs, labels) in enumerate(train_loader):\n",
    "        # pass inputs to device, clear gradients\n",
    "        inputs, labels = inputs.to(args.device, non_blocking=True),\\\n",
    "                        labels.to(args.device, non_blocking=True)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward-backward pass and update\n",
    "        outputs = model(inputs)\n",
    "        minibatch_loss = criterion(outputs, labels)\n",
    "        minibatch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # keep track of round loss/accuracy\n",
    "            train_loss += minibatch_loss.item()*outputs.shape[0]\n",
    "            _, pred_labels = torch.max(outputs, 1)\n",
    "            train_acc += torch.sum(torch.eq(pred_labels.view(-1), labels)).item()\n",
    "            \n",
    "    with torch.no_grad():   \n",
    "        # inference after round \n",
    "        train_loss, train_acc = train_loss/len(train_dataset), train_acc/len(train_dataset)       \n",
    "        val_loss, (val_acc, val_per_class) = infer.get_loss_n_accuracy(model, criterion, val_loader, args)                                  \n",
    "        scheduler.step(val_loss)\n",
    "        # log/print data\n",
    "        writer.add_scalar('Validation/Loss', val_loss, rnd)\n",
    "        writer.add_scalar('Validation/Accuracy', val_acc, rnd)\n",
    "        writer.add_scalar('Training/Loss', train_loss, rnd)\n",
    "        writer.add_scalar('Training/Accuracy', train_acc, rnd)\n",
    "        print(f'|Train/Valid Loss: {train_loss:.3f} / {val_loss:.3f}|', end='--')\n",
    "        print(f'|Train/Valid Acc: {train_acc:.3f} / {val_acc:.3f}|', end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time.record()\n",
    "torch.cuda.synchronize()\n",
    "time_elapsed_secs = start_time.elapsed_time(end_time)/10**3\n",
    "time_elapsed_mins = time_elapsed_secs/60\n",
    "print(f'Training took {time_elapsed_secs:.2f} seconds / {time_elapsed_mins:.2f} minutes')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

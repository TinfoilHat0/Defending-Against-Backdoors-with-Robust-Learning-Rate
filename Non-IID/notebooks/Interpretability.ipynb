{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, '../src/')\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils import vector_to_parameters, parameters_to_vector\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import utils\n",
    "from torchsummary import summary\n",
    "import models\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import shutil\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils import H5Dataset\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torchvision import transforms\n",
    "\n",
    "from captum.attr import IntegratedGradients\n",
    "from captum.attr import GradientShap\n",
    "from captum.attr import Occlusion\n",
    "from captum.attr import NoiseTunnel\n",
    "from captum.attr import visualization as viz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import cm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.enabled = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args:\n",
    "    model_file='niid_nodefense_model.pt'\n",
    "    data='fedemnist'\n",
    "    bs = 64\n",
    "    device = 'cuda:0'\n",
    "    lr = 0\n",
    "    moment = 0.9\n",
    "    wd = 0\n",
    "    epochs=50\n",
    "    nesterov = True\n",
    "    base_class = 1\n",
    "    target_class = 4\n",
    "    poison_frac = 0.05\n",
    "    pattern_type='apple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset = utils.get_datasets(args.data)\n",
    "idxs = (val_dataset.targets == args.base_class).nonzero().flatten().tolist()\n",
    "poisoned_val_set = utils.DatasetSplit(copy.deepcopy(val_dataset), idxs)\n",
    "utils.poison_dataset(poisoned_val_set.dataset, args, poison_all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader =  DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False, num_workers=2, pin_memory=True)\n",
    "poisoned_val_loader = DataLoader(poisoned_val_set, batch_size=args.bs, shuffle=False, num_workers=0, pin_memory=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(args.model_file)\n",
    "model.eval()\n",
    "criterion = nn.CrossEntropyLoss().to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (imgs, labels) = next(enumerate(poisoned_val_loader))\n",
    "idx = (labels==args.target_class).nonzero()[36].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3963814c18>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = imgs[idx]\n",
    "plt.imshow(img.squeeze(0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img.view(1, 1, 28, 28).to(args.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = F.softmax(output, dim=1)\n",
    "prediction_score, pred_label_idx = torch.topk(output, 1)\n",
    "\n",
    "pred_label_idx.squeeze_()\n",
    "predicted_label = pred_label_idx.item()\n",
    "print('Predicted:', predicted_label, '(', prediction_score.squeeze().item(), ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "integrated_gradients = IntegratedGradients(model)\n",
    "attributions_ig = integrated_gradients.attribute(img, target=pred_label_idx, n_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cmap = cm.get_cmap('inferno')\n",
    "gradient_shap = GradientShap(model)\n",
    "\n",
    "# Defining baseline distribution of images\n",
    "rand_img_dist = torch.cat([img * 0, img * 1])\n",
    "\n",
    "attributions_gs = gradient_shap.attribute(img,\n",
    "                                          n_samples=100,\n",
    "                                          stdevs=0.0001,\n",
    "                                          baselines=rand_img_dist,\n",
    "                                          target=pred_label_idx)\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(attributions_gs.squeeze().cpu().detach().numpy().reshape(28, 28, 1),\n",
    "                                      img.squeeze().cpu().detach().numpy(),\n",
    "                                      [\"original_image\", \"heat_map\"],\n",
    "                                      [\"all\", \"positive\"],\n",
    "                                      cmap=default_cmap,\n",
    "                                      show_colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_cmap = cm.get_cmap('Greens')\n",
    "\n",
    "_ = viz.visualize_image_attr_multiple(attributions_ig.squeeze().cpu().detach().numpy().reshape(28, 28, 1),\n",
    "                            img.squeeze().cpu().detach().numpy(), \n",
    "                             [\"original_image\", \"heat_map\"],\n",
    "                            [\"all\", \"positive\"],\n",
    "                            cmap=default_cmap,\n",
    "                            show_colorbar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python37364bitbaseconda2893f7c78e4248a9bda8fc39f732a94d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
